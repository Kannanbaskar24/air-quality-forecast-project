{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5fb5e2b-bb08-46fd-a010-1ac765dc23df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install prophet xgboost scikit-learn joblib tensorflow statsmodels --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9472809-75b8-4f80-8b79-b2e30406761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# 02_modelling.ipynb - Forecasting Models (Corrected)\n",
    "# ===============================================================\n",
    "\n",
    "# STEP 2: Imports\n",
    "import os, warnings, joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "try:\n",
    "    plt.style.use(\"seaborn-v0_8\")\n",
    "except:\n",
    "    plt.style.use(\"default\")\n",
    "\n",
    "# Models\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from prophet import Prophet\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e21a477-9c89-437f-8003-2cd19667effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Ensure models folder exists\n",
    "os.makedirs(\"../models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "986f62d7-af75-414b-a16c-646916b172eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (29531, 18)\n",
      "Columns: Index(['City', 'PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3',\n",
      "       'Benzene', 'Toluene', 'Xylene', 'AQI', 'AQI_Bucket', 'dayofweek',\n",
      "       'month', 'year'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NH3</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>Benzene</th>\n",
       "      <th>Toluene</th>\n",
       "      <th>Xylene</th>\n",
       "      <th>AQI</th>\n",
       "      <th>AQI_Bucket</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>165.63375</td>\n",
       "      <td>309.894886</td>\n",
       "      <td>0.92000</td>\n",
       "      <td>18.220</td>\n",
       "      <td>17.15</td>\n",
       "      <td>4.590000</td>\n",
       "      <td>0.92</td>\n",
       "      <td>27.64000</td>\n",
       "      <td>84.46375</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>472.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>Chennai</td>\n",
       "      <td>165.63375</td>\n",
       "      <td>309.894886</td>\n",
       "      <td>16.30000</td>\n",
       "      <td>15.390</td>\n",
       "      <td>22.68</td>\n",
       "      <td>4.590000</td>\n",
       "      <td>1.17</td>\n",
       "      <td>9.20000</td>\n",
       "      <td>11.35000</td>\n",
       "      <td>0.17</td>\n",
       "      <td>12.44</td>\n",
       "      <td>4.920000</td>\n",
       "      <td>472.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>165.63375</td>\n",
       "      <td>309.894886</td>\n",
       "      <td>41.05125</td>\n",
       "      <td>36.390</td>\n",
       "      <td>80.18</td>\n",
       "      <td>33.850000</td>\n",
       "      <td>2.82</td>\n",
       "      <td>9.25000</td>\n",
       "      <td>41.68000</td>\n",
       "      <td>7.38</td>\n",
       "      <td>23.37</td>\n",
       "      <td>8.737708</td>\n",
       "      <td>472.0</td>\n",
       "      <td>Severe</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>Lucknow</td>\n",
       "      <td>165.63375</td>\n",
       "      <td>309.894886</td>\n",
       "      <td>2.11000</td>\n",
       "      <td>13.460</td>\n",
       "      <td>4.57</td>\n",
       "      <td>29.353333</td>\n",
       "      <td>2.82</td>\n",
       "      <td>29.49125</td>\n",
       "      <td>25.92000</td>\n",
       "      <td>1.35</td>\n",
       "      <td>3.93</td>\n",
       "      <td>4.920000</td>\n",
       "      <td>467.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>165.63375</td>\n",
       "      <td>309.894886</td>\n",
       "      <td>2.68500</td>\n",
       "      <td>15.395</td>\n",
       "      <td>27.38</td>\n",
       "      <td>24.856667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.49125</td>\n",
       "      <td>18.32500</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>463.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 City      PM2.5        PM10        NO     NO2    NOx  \\\n",
       "Date                                                                    \n",
       "2015-01-01  Ahmedabad  165.63375  309.894886   0.92000  18.220  17.15   \n",
       "2015-01-01    Chennai  165.63375  309.894886  16.30000  15.390  22.68   \n",
       "2015-01-01      Delhi  165.63375  309.894886  41.05125  36.390  80.18   \n",
       "2015-01-01    Lucknow  165.63375  309.894886   2.11000  13.460   4.57   \n",
       "2015-01-01     Mumbai  165.63375  309.894886   2.68500  15.395  27.38   \n",
       "\n",
       "                  NH3    CO       SO2        O3  Benzene  Toluene    Xylene  \\\n",
       "Date                                                                          \n",
       "2015-01-01   4.590000  0.92  27.64000  84.46375     0.00     0.02  0.000000   \n",
       "2015-01-01   4.590000  1.17   9.20000  11.35000     0.17    12.44  4.920000   \n",
       "2015-01-01  33.850000  2.82   9.25000  41.68000     7.38    23.37  8.737708   \n",
       "2015-01-01  29.353333  2.82  29.49125  25.92000     1.35     3.93  4.920000   \n",
       "2015-01-01  24.856667  0.00  29.49125  18.32500     0.00     0.00  0.000000   \n",
       "\n",
       "              AQI AQI_Bucket  dayofweek  month  year  \n",
       "Date                                                  \n",
       "2015-01-01  472.0        NaN          3      1  2015  \n",
       "2015-01-01  472.0        NaN          3      1  2015  \n",
       "2015-01-01  472.0     Severe          3      1  2015  \n",
       "2015-01-01  467.5        NaN          3      1  2015  \n",
       "2015-01-01  463.0        NaN          3      1  2015  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 4: Load processed dataset from Module 1\n",
    "df = pd.read_csv(\"../data/processed/air_quality_cleaned.csv\", index_col=0, parse_dates=True)\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ba658d9-90a8-4bb0-8357-b25d540592fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: Evaluation function\n",
    "def evaluate(y_true, y_pred):\n",
    "    if not isinstance(y_pred, pd.Series):\n",
    "        y_pred = pd.Series(y_pred, index=y_true.index)\n",
    "    df_eval = pd.concat([y_true, y_pred], axis=1).dropna()\n",
    "    if df_eval.empty:\n",
    "        return (np.nan, np.nan)\n",
    "    y_true_clean, y_pred_clean = df_eval.iloc[:,0], df_eval.iloc[:,1]\n",
    "    mae = mean_absolute_error(y_true_clean, y_pred_clean)\n",
    "    rmse = sqrt(mean_squared_error(y_true_clean, y_pred_clean))\n",
    "    return mae, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7c7de44-7314-42e0-adbd-fd68d3b62feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Training models for PM2.5\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:25:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:25:26 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for PM2.5: LSTM\n",
      "Saved LSTM model for PM2.5\n",
      "\n",
      "============================================================\n",
      "Training models for PM10\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:25:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:25:35 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for PM10: LSTM\n",
      "Saved LSTM model for PM10\n",
      "\n",
      "============================================================\n",
      "Training models for NO\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:25:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:25:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for NO: LSTM\n",
      "Saved LSTM model for NO\n",
      "\n",
      "============================================================\n",
      "Training models for NO2\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:25:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:25:54 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for NO2: LSTM\n",
      "Saved LSTM model for NO2\n",
      "\n",
      "============================================================\n",
      "Training models for NOx\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:26:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:26:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for NOx: LSTM\n",
      "Saved LSTM model for NOx\n",
      "\n",
      "============================================================\n",
      "Training models for NH3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:26:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:26:15 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for NH3: ARIMA\n",
      "Saved ARIMA model for NH3\n",
      "\n",
      "============================================================\n",
      "Training models for CO\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:26:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:26:27 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for CO: LSTM\n",
      "Saved LSTM model for CO\n",
      "\n",
      "============================================================\n",
      "Training models for SO2\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:26:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:26:37 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for SO2: LSTM\n",
      "Saved LSTM model for SO2\n",
      "\n",
      "============================================================\n",
      "Training models for O3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:26:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:26:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for O3: Prophet\n",
      "Saved Prophet model for O3\n",
      "\n",
      "============================================================\n",
      "Training models for Benzene\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:26:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:26:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for Benzene: Prophet\n",
      "Saved Prophet model for Benzene\n",
      "\n",
      "============================================================\n",
      "Training models for Toluene\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:27:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:27:07 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for Toluene: LSTM\n",
      "Saved LSTM model for Toluene\n",
      "\n",
      "============================================================\n",
      "Training models for Xylene\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:27:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:27:17 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for Xylene: ARIMA\n",
      "Saved ARIMA model for Xylene\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import needed modules if not done already\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from prophet import Prophet\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import joblib\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "pollutants = ['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3', 'Benzene', 'Toluene', 'Xylene']\n",
    "\n",
    "for pollutant in pollutants:\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Training models for {pollutant}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    series = df[pollutant].dropna()\n",
    "\n",
    "    # Fix: Drop duplicate timestamps indices to avoid reindex errors\n",
    "    series = series[~series.index.duplicated(keep='first')]  \n",
    "\n",
    "    # Set daily frequency for time series\n",
    "    series = series.asfreq(\"D\")\n",
    "\n",
    "    if len(series) < 100:\n",
    "        print(f\"Skipping {pollutant} (not enough data)\")\n",
    "        continue\n",
    "\n",
    "    train_size = int(len(series) * 0.8)\n",
    "    train, test = series[:train_size], series[train_size:]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # Persistence baseline\n",
    "    persistence_preds = test.shift(1).fillna(method=\"bfill\")\n",
    "    results[\"Persistence\"] = evaluate(test, persistence_preds)\n",
    "\n",
    "    # ARIMA model\n",
    "    try:\n",
    "        arima_model = ARIMA(train, order=(5,1,0))\n",
    "        arima_fit = arima_model.fit()\n",
    "        arima_forecast = pd.Series(arima_fit.forecast(steps=len(test)), index=test.index)\n",
    "        results[\"ARIMA\"] = evaluate(test, arima_forecast)\n",
    "    except Exception as e:\n",
    "        print(\"ARIMA failed:\", e)\n",
    "        results[\"ARIMA\"] = (np.nan, np.nan)\n",
    "\n",
    "    # Prophet model\n",
    "    try:\n",
    "        prophet_df = pd.DataFrame({\"ds\": train.index, \"y\": train.values})\n",
    "        prophet_df[\"ds\"] = prophet_df[\"ds\"].dt.tz_localize(None)\n",
    "        prophet_model = Prophet(daily_seasonality=True, weekly_seasonality=True, yearly_seasonality=True)\n",
    "        prophet_model.fit(prophet_df)\n",
    "        future = prophet_model.make_future_dataframe(periods=len(test), freq=\"D\")\n",
    "        future[\"ds\"] = future[\"ds\"].dt.tz_localize(None)\n",
    "        forecast = prophet_model.predict(future)\n",
    "        prophet_forecast = forecast.set_index(\"ds\")[\"yhat\"].iloc[-len(test):]\n",
    "        prophet_forecast.index = test.index\n",
    "        results[\"Prophet\"] = evaluate(test, prophet_forecast)\n",
    "    except Exception as e:\n",
    "        print(\"Prophet failed:\", e)\n",
    "        results[\"Prophet\"] = (np.nan, np.nan)\n",
    "\n",
    "    # XGBoost model\n",
    "    try:\n",
    "        def make_lags(series, n_lags=7):\n",
    "            df_lag = pd.DataFrame({\"y\": series})\n",
    "            for lag in range(1, n_lags+1):\n",
    "                df_lag[f\"lag_{lag}\"] = df_lag[\"y\"].shift(lag)\n",
    "            return df_lag.dropna()\n",
    "\n",
    "        lags = make_lags(series, n_lags=7)\n",
    "        train_lags = lags.loc[train.index.min():train.index.max()]\n",
    "        test_lags = lags.loc[test.index.min():test.index.max()]\n",
    "\n",
    "        X_train, y_train = train_lags.drop(columns=\"y\"), train_lags[\"y\"]\n",
    "        X_test, y_test = test_lags.drop(columns=\"y\"), test_lags[\"y\"]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_s = scaler.fit_transform(X_train)\n",
    "        X_test_s = scaler.transform(X_test)\n",
    "\n",
    "        xgb_model = xgb.XGBRegressor(n_estimators=300, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "        xgb_model.fit(X_train_s, y_train)\n",
    "\n",
    "        xgb_preds = pd.Series(xgb_model.predict(X_test_s), index=X_test.index)\n",
    "        results[\"XGBoost\"] = evaluate(y_test, xgb_preds)\n",
    "    except Exception as e:\n",
    "        print(\"XGBoost failed:\", e)\n",
    "        results[\"XGBoost\"] = (np.nan, np.nan)\n",
    "\n",
    "    # LSTM model\n",
    "    try:\n",
    "        def create_sequences(values, n_steps=7):\n",
    "            X, y = [], []\n",
    "            for i in range(len(values) - n_steps):\n",
    "                X.append(values[i:i+n_steps])\n",
    "                y.append(values[i+n_steps])\n",
    "            return np.array(X), np.array(y)\n",
    "\n",
    "        values = series.values\n",
    "        n_steps = 7\n",
    "        X_all, y_all = create_sequences(values, n_steps)\n",
    "        split_i = int(len(X_all) * 0.8)\n",
    "        X_train_seq, X_test_seq = X_all[:split_i], X_all[split_i:]\n",
    "        y_train_seq, y_test_seq = y_all[:split_i], y_all[split_i:]\n",
    "\n",
    "        X_train_seq = X_train_seq.reshape((X_train_seq.shape[0], X_train_seq.shape[1], 1))\n",
    "        X_test_seq  = X_test_seq.reshape((X_test_seq.shape[0], X_test_seq.shape[1], 1))\n",
    "\n",
    "        lstm = Sequential()\n",
    "        lstm.add(LSTM(50, activation=\"relu\", input_shape=(n_steps,1)))\n",
    "        lstm.add(Dense(1))\n",
    "        lstm.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "        lstm.fit(X_train_seq, y_train_seq, epochs=10, verbose=0)\n",
    "\n",
    "        lstm_preds = lstm.predict(X_test_seq, verbose=0).flatten()\n",
    "        lstm_index = series.index[-len(y_test_seq):]\n",
    "        lstm_preds_series = pd.Series(lstm_preds, index=lstm_index)\n",
    "        results[\"LSTM\"] = evaluate(series.loc[lstm_index], lstm_preds_series)\n",
    "    except Exception as e:\n",
    "        print(\"LSTM failed:\", e)\n",
    "        results[\"LSTM\"] = (np.nan, np.nan)\n",
    "\n",
    "    # Save best model\n",
    "    results_df = pd.DataFrame(results, index=[\"MAE\",\"RMSE\"]).T\n",
    "    all_results[pollutant] = results_df\n",
    "    best_model = results_df[\"RMSE\"].dropna().idxmin()\n",
    "    print(f\"Best model for {pollutant}: {best_model}\")\n",
    "\n",
    "    # Save models correctly\n",
    "    if best_model == \"ARIMA\":\n",
    "        joblib.dump(arima_fit, f\"../models/{pollutant}_arima.pkl\")\n",
    "    elif best_model == \"Prophet\":\n",
    "        joblib.dump(prophet_model, f\"../models/{pollutant}_prophet.pkl\")\n",
    "    elif best_model == \"XGBoost\":\n",
    "        joblib.dump(xgb_model, f\"../models/{pollutant}_xgb.pkl\")\n",
    "        joblib.dump(scaler, f\"../models/{pollutant}_xgb_scaler.pkl\")\n",
    "    elif best_model == \"LSTM\":\n",
    "        lstm.save(f\"../models/{pollutant}_lstm.keras\")\n",
    "    elif best_model == \"Persistence\":\n",
    "        joblib.dump(series, f\"../models/{pollutant}_persistence.pkl\")\n",
    "\n",
    "    print(f\"Saved {best_model} model for {pollutant}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef668ff0-65ea-4dfc-8125-e53540821bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PM2.5</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>21.569968</td>\n",
       "      <td>29.384597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PM10</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>48.896476</td>\n",
       "      <td>63.847904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>9.357396</td>\n",
       "      <td>11.629328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO2</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>12.710144</td>\n",
       "      <td>16.41996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOx</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>15.892867</td>\n",
       "      <td>20.196671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NH3</th>\n",
       "      <td>ARIMA</td>\n",
       "      <td>10.327133</td>\n",
       "      <td>14.59398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.45242</td>\n",
       "      <td>0.592358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SO2</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>5.861742</td>\n",
       "      <td>7.626662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O3</th>\n",
       "      <td>Prophet</td>\n",
       "      <td>13.982668</td>\n",
       "      <td>17.801481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Benzene</th>\n",
       "      <td>Prophet</td>\n",
       "      <td>1.985413</td>\n",
       "      <td>2.38367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toluene</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>6.517224</td>\n",
       "      <td>7.901838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xylene</th>\n",
       "      <td>ARIMA</td>\n",
       "      <td>1.805651</td>\n",
       "      <td>2.348106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Best Model        MAE       RMSE\n",
       "PM2.5         LSTM  21.569968  29.384597\n",
       "PM10          LSTM  48.896476  63.847904\n",
       "NO            LSTM   9.357396  11.629328\n",
       "NO2           LSTM  12.710144   16.41996\n",
       "NOx           LSTM  15.892867  20.196671\n",
       "NH3          ARIMA  10.327133   14.59398\n",
       "CO            LSTM    0.45242   0.592358\n",
       "SO2           LSTM   5.861742   7.626662\n",
       "O3         Prophet  13.982668  17.801481\n",
       "Benzene    Prophet   1.985413    2.38367\n",
       "Toluene       LSTM   6.517224   7.901838\n",
       "Xylene       ARIMA   1.805651   2.348106"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 7: Summarize best models\n",
    "summary = {}\n",
    "for pollutant, res in all_results.items():\n",
    "    best = res[\"RMSE\"].dropna().idxmin()\n",
    "    summary[pollutant] = {\n",
    "        \"Best Model\": best,\n",
    "        \"MAE\": res.loc[best, \"MAE\"],\n",
    "        \"RMSE\": res.loc[best, \"RMSE\"]\n",
    "    }\n",
    "\n",
    "summary_df = pd.DataFrame(summary).T\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e0908d-0cc5-404e-98b3-12aad0db032c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
